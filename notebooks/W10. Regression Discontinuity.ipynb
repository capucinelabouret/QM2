{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJuJsd4XOtlw"
      },
      "source": [
        "# Regression Discontinuity\n",
        "\n",
        "## *Workshop 10*  [![Open In Colab](https://github.com/oballinger/QM2/blob/main/colab-badge.png?raw=1)](https://colab.research.google.com/github/oballinger/QM2/blob/main/notebooks/W10.%20Regression%20Discontinuity.ipynb)\n",
        "\n",
        "In this final week, we're going to look at Regression Discontinuity Designs (RDD). We'll look into discontinuities in two types of variables:\n",
        "\n",
        "1. Spatial discontinuities\n",
        "2. Temporal discontinuities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2CWjVI6POtmA",
        "outputId": "f3ab21bf-9a38-4742-f754-8dc18794f02c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3141k  100 3141k    0     0  3931k      0 --:--:-- --:--:-- --:--:-- 3931k\n",
            "<?xml version='1.0' encoding='UTF-8'?><Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Details>No such object: qm2/wk10/county_labor.csv-o</Details></Error>curl: (6) Could not resolve host: data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  9177  100  9177    0     0  33281      0 --:--:-- --:--:-- --:--:-- 33370\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1728  100  1728    0     0   5667      0 --:--:-- --:--:-- --:--:--  5702\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!curl https://storage.googleapis.com/qm2/wk10/geojson-counties-fips.json -o data/geojson-counties-fips.json\n",
        "!curl https://storage.googleapis.com/qm2/wk10/county_labor.csv-o data/county_labor.csv\n",
        "!curl https://storage.googleapis.com/qm2/rdd/drinking.csv -o data/drinking.csv\n",
        "!curl https://storage.googleapis.com/qm2/rdd/sheepskin.csv -o data/sheepskin.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "DIUB_vcTOtmH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import style\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.formula.api as smf\n",
        "import geopandas as gpd\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "style.use(\"fivethirtyeight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKkeiKw0OtmI"
      },
      "source": [
        "# Spatial Discontinuities\n",
        "\n",
        "Last week, we set up a difference model and made causal claims about the effect of minimum wage laws on unemployment. We did this by treating Pennsylvania as a control group for New Jersey on the basis that they had similar trends in unemployment before the minimum wage law, and diverging trends after, and no other shock coincided with this policy.\n",
        "\n",
        "We could still poke some holes in that-- NJ seems to have fared worse than PA after the 2008 crisis; maybe more people work in finance in NJ. Indeed, Jersey City is across the water from Manhattan, America's financial centre. Bankers would be hard hit by a financial crisis, but are probably not that affected by minimum wage laws. Conversely, Pennsylvania is the 3rd largest coal-producing state in the U.S.-- coal miners are probably less affected by financial crises, but more likely to be earning minimum wage. As such, increasing the minimum wage in a place where most people are bankers probably has less of an effect on unemployment compared to an area where everyone is a coal miner.\n",
        "\n",
        "Running a state-level analysis is subject to this sort of selection bias, since by looking at state averages we're effectively comparing places like Jersey City to places like [Centralia](https://en.wikipedia.org/wiki/Centralia,_Pennsylvania), a coal-mining town in central Pennsylvania which saw its population decline from 1000 in 1980 to just five residents in 2020. So the next step in our analysis might be to try to compare apples to apples. There are a number of ways of doing this-- we could look at the unemployment rate by industry, for example. But what if we didn't want to rely on pre-trends, or if we didn't even have data prior to the treatment? This is often the case\n",
        "\n",
        "To build a more valid counterfactual, we can drill even deeper to find even more similar comparison groups using a **Regression Discontinuity Design (RDD)** using county (rather than state) level data.\n",
        "\n",
        "> **[Regression Discontinuity Designs](https://www.princeton.edu/~davidlee/wp/RDDEconomics.pdf)** are a method of estimating treatment effects in a nonexperimental setting where treatment is determined by whether an observed “assignment” variable exceeds a known cutoff point. If the cutoff is exogenous to the treatment, observations in the vicinity of this cutoff are likely to be very similar, and assignment to the treatment or control group can be considered as good as random.\n",
        "\n",
        "RDD models generally take the following form:\n",
        "\n",
        "$$\\huge Y_{i} = \\beta_0 + \\beta_1 R_i + \\beta_2 T_i + \\varepsilon_{i}$$\n",
        "\n",
        "$$\\large T_i=    \\begin{cases}\n",
        "      1 & R_i>c\\\\\n",
        "      0 & R_i<c\\\\\n",
        "    \\end{cases} $$\n",
        "\n",
        "Where R is the \"running variable\", T is the treatment variable, and c is a cutoff in the running variable assigning observations to the \"treatment\" or \"control\" groups.\n",
        "\n",
        "In our case, the treatment is the minimum wage law passed in NJ in 2014. We want to be looking at the period after this to pick up on any changes in employment. The **assignment variable** in this case could be the distance of a county to the border between the two states, and the sharp cutoff would be the border itself. Counties on the border counties are probably much more similar to each other than other, farther away counties: this would exclude both Jersey City (in the far east of NJ) and Centralia (in the centre of PA).\n",
        "\n",
        "Indeed, several cities are divided by the border between these states including Philladelphia, the capital city of Pennsylvania:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gY1FmgXiOtmL",
        "outputId": "00eaad31-d1bc-44df-a885-468197b5a0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421,
          "referenced_widgets": [
            "fcdab42e4ff84260b4f022902bf5fbbb",
            "afe2c4d1842e43ca8ed7c6e4753524d4",
            "09b163b94e8b4fde9552a9b64f69ae91",
            "711a03f92da241ac8974432c9cf4ae4f",
            "afa1c7a4f62c4c3588fd3b862731538e",
            "8252e0c36b434711891ee0428a7aba1e",
            "fad647645d244b648fbb6a00559f178a",
            "306361b3b81449ffa99c5a3ae577d3e0"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map(center=[39.95279958991338, -75.1341365382268], controls=(ZoomControl(options=['position', 'zoom_in_text', …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcdab42e4ff84260b4f022902bf5fbbb"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "from ipyleaflet import Map, Marker, basemaps, basemap_to_tiles\n",
        "Map(basemap=basemap_to_tiles(\n",
        "    basemaps.Esri.WorldImagery),\n",
        "  center=(39.95279958991338, -75.1341365382268),\n",
        "  zoom=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3_SUBaJOtmM"
      },
      "source": [
        "On the left side of the river is Philladelphia, PA, while on the right side is Camden, NJ. The code below uses the county shapefile we used before to isolate the counties in NJ and PA that are on the border."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TgzL3RNPOtmN",
        "outputId": "d2822147-dcd8-4813-8e11-9c4e2a43f9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c4dd2e34e7e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcounties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/wk10/county_labor.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'county_fips'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read in the county labor data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/geojson-counties-fips.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read in the counties shapefile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'34'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'42'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# new jersey = 34, pennsylvania = 42, new york = 36\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/wk10/county_labor.csv'"
          ]
        }
      ],
      "source": [
        "counties=pd.read_csv('data/wk10/county_labor.csv', dtype={'county_fips':str}) # read in the county labor data\n",
        "shp = gpd.read_file('data/geojson-counties-fips.json') # read in the counties shapefile\n",
        "\n",
        "subset=shp[shp['STATE'].isin(['34','42'])] # new jersey = 34, pennsylvania = 42, new york = 36\n",
        "\n",
        "subset['neighbors']= 0 # create a new column called neighbors\n",
        "\n",
        "for index, row in subset.iterrows():  # iterate through each row in the counties shapefile\n",
        "    buffered= row['geometry'].buffer(0.1) # create a buffer around the county so that it overlaps with its neighbors\n",
        "    neighbors = list(set(subset[subset.geometry.overlaps(buffered)].STATE.tolist()).difference([row.STATE])) # check which counties overlap with the buffer, grab the state code, and remove the current county's state code\n",
        "    subset.at[index, \"neighbors\"] = \", \".join(neighbors) # add the list of neighbors to the neighbors column\n",
        "\n",
        "subset['border']=np.where(subset['neighbors']=='',0,1) # create a new column called border that is 1 if the county is on the border and 0 if it is not\n",
        "\n",
        "subset['viscol']=subset['STATE'].astype(int)+subset['border'] # create a new column that combines the state code and the border column\n",
        "subset.plot(column='viscol',legend=False, figsize=(20,10), cmap='RdYlGn') # plot the counties and color them by the border column\n",
        "plt.title('Border Counties in New Jersey and Pennsylvania', fontsize=20) # add a title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWsyP0IUOtmP"
      },
      "source": [
        "We can now restrict our sample to only include counties within a set distance the border, and set up a regression discontinuity design in which:\n",
        "\n",
        "* unemployment is the dependent variable.\n",
        "* state (NJ/PA) is the treatment variable.\n",
        "* distance from the border is the running variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEMuKJQxOtmQ"
      },
      "outputs": [],
      "source": [
        "border_counties=subset[subset['border']==1]['id'].tolist() # create a list of the border counties\n",
        "rdd=counties[(counties['year']>2007)&(counties['county_fips'].isin(border_counties))] # subset the counties data to only include border counties and years after 2007\n",
        "rdd_model = ols('unemployment ~ C(state)', rdd[rdd['year']>2014]).fit()\n",
        "\n",
        "print(rdd_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llkgwJd2OtmS"
      },
      "source": [
        "\n",
        "This gives us a much better idea of the impact of the minimum wage law by discarding counties that are very far away from eachother and thus dissimilar. We can see that border counties in Pennsylvania saw a 0.66% *increase* in unemployment relative to border counties in New Jersey, in the years following the latter's implementation of the minimum wage increase. This difference, however, is not statistically significant.\n",
        "\n",
        "This example captures the basic intuition behind regression discontinuity, but we might worry that the minimum wage law isn't the only thing that changes as the discontinutiy (i.e., isn't the only thing that changes between NJ and PA).\n",
        "\n",
        "It is quite common to use distance as a running variable in RDD, and if you're interested in a review of the literature on spatial RDD models check out [this article](https://www.jstor.org/stable/24572845).\n",
        "\n",
        "To get a firm grasp of the intuition and mechanics behind RDD, we'll use a more straightforward example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyEY0aOxOtmT"
      },
      "source": [
        "## Is Alcohol Killing You?\n",
        "\n",
        "A very relevant public policy question is what should be the minimal drinking age. Most countries, Brazil included, set it to be 18 year, but in the US (most states) it is currently 21. So, is it the case that the US is being overly prudent and that they should lower their minimal drinking age? Or is it the case that other countries should make their legal drinking age higher?\n",
        "\n",
        "One way to look at this question is from a [mortality rate perspective (Carpenter and Dobkin, 2009)](https://www.aeaweb.org/articles?id=10.1257/app.1.1.164). From the public policy standpoint, one could argue that we should lower the mortality rate as much as possible. If alcohol consumption increases the mortality rate by a lot, we should avoid lowering the minimum drinking age. This would be consistent with the objective of lowering deaths caused by alcohol consumption.\n",
        "\n",
        "To estimate the impacts of alcohol on death, we could use the fact that legal drinking age imposes a discontinuity on nature. In the US, those just under 21 years don't drink (or drink much less) while those just older than 21 do drink. This means that the probability of drinking jumps at 21 years and that is something we can explore with an RDD.\n",
        "\n",
        "To do so we can grab some mortality data aggregated by age. Each row is the average age of a group of people and the average mortality by all causes (`all`), by moving vehicle accident (`mva`) and by suicide (`suicide`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spYKR27kOtmU"
      },
      "outputs": [],
      "source": [
        "drinking = pd.read_csv(\"./data/drinking.csv\")\n",
        "drinking.head()[[\"agecell\", \"all\", \"mva\", \"suicide\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBs73rPSOtmV"
      },
      "source": [
        "Just to aid visibility (and for another important reason we will see later) we will centralize the running variable `agecell` at the threshold 21."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbg0AR9zOtmW"
      },
      "outputs": [],
      "source": [
        "drinking[\"agecell\"] -= 21"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diBzbOHJOtmX"
      },
      "source": [
        "If we plot the multiple outcome variables (`all`, `mva`, `suicide`) with the runing variable on the x axis, we get some visual cue about some sort of jump in mortality as we cross the legal drinking age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6zQOlv1OtmY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "ax = plt.subplot(3,1,1)\n",
        "drinking.plot.scatter(x=\"agecell\", y=\"all\", ax=ax)\n",
        "plt.title(\"Death Cause by Age (Centered at 0)\")\n",
        "\n",
        "ax = plt.subplot(3,1,2, sharex=ax)\n",
        "drinking.plot.scatter(x=\"agecell\", y=\"mva\", ax=ax)\n",
        "\n",
        "ax = plt.subplot(3,1,3, sharex=ax)\n",
        "drinking.plot.scatter(x=\"agecell\", y=\"suicide\", ax=ax);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swsgykoUOtma"
      },
      "source": [
        "There are some cues, but we need more than that. What exactly is the effect of drinking on mortality at the threshold? And what is the standard error on that estimate?\n",
        "\n",
        "## RDD Estimation\n",
        "\n",
        "The key assumption that RDD relies on is the smoothness of the potential outcome at the threshold. We can think of RDD as a local randomized trial. For those at the threshold, the treatment could have gone either way and, by chance, some people fell below the threshold, and some people fell above. In our example, at the same point in time, some people are just above 21 years and some people are just below 21. What determines this is if someone was born some days later or not, which is pretty random. For this reason, RDD provides a very compelling causal story. It is not the golden standard of RCT, but it is close.\n",
        "\n",
        "Now, to estimate the treatment effect at the threshold, all we need to do is estimate both of the limits in the formula above and compare them. The simplest way to do that is by running a linear regression\n",
        "\n",
        "\n",
        "To make it work, we interact a dummy for being above the threshold with the running variable\n",
        "\n",
        "$\n",
        "y_i = \\beta_0 + \\beta_1 r_i + \\beta_2 \\mathcal{1}\\{r_i>c\\} + \\beta_3 \\mathcal{1}\\{r_i>c\\} r_i\n",
        "$\n",
        "\n",
        "Essentially, this is the same as fitting a linear regression above the threshold and another below it. The parameter $\\beta_0$ is the intercept of the regression below the threshold and $\\beta_0+\\beta_2$ is the intercept for the regression above the threshold.\n",
        "\n",
        "Here is where the trick of centering the running variable at the threshold comes into play. After this pre-processing step, the threshold becomes zero. This causes the intercept $\\beta_0$ to be the predicted value at the threshold, for the regression below it. By the same reasoning, $\\beta_0+\\beta_2$ is the limit of the outcome from above.\n",
        "\n",
        "Here is what this looks like in code for the case where we want to estimate the effect of alcohol consumption on death by all causes at 21 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwC16seyOtmc"
      },
      "outputs": [],
      "source": [
        "rdd_df = drinking.assign(threshold=(drinking[\"agecell\"] > 0).astype(int))\n",
        "model = smf.wls(\"all~ agecell * threshold \", rdd_df).fit()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pct6cIIVOtmd"
      },
      "source": [
        "This model is telling us that mortality increases by 7.6627 points with the consumption of alcohol. Another way of putting this is that alcohol increases the chance of death by all causes by 8% $(100*((7.6627+93.6184)/93.6184 - 1))$. Notice that this also gives us standard errors for our causal effect estimate. In this case, the effect is statistically significant, since the p-value is below 0.01. We can calculate the treatment effect programattically as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnWYo0bfOtme"
      },
      "outputs": [],
      "source": [
        "ate_pct = 100*((model.params[\"threshold\"] + model.params[\"Intercept\"])/model.params[\"Intercept\"] - 1)\n",
        "\n",
        "print(\"Alcohol increases the chance of death by all causes by {}%\".format(np.round(ate_pct,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw2Lu2GWOtmf"
      },
      "source": [
        "\n",
        "If we want to verify this model visually, we can show the predicted values on the data that we have. You can see that it is as though we had 2 regression models: one for those above the threshold and one for below it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RERbQVB2Otmg"
      },
      "outputs": [],
      "source": [
        "ax = drinking.plot.scatter(x=\"agecell\", y=\"all\", color=\"C0\")\n",
        "drinking.assign(predictions=model.fittedvalues).plot(x=\"agecell\", y=\"predictions\", ax=ax, color=\"C1\")\n",
        "plt.title(f\"Impact of Alcohol on Death: {np.round(ate_pct, 2)}% \\n p={np.round(model.pvalues['threshold'], 3)}, R2={np.round(model.rsquared, 3)}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5HWnsCtOtmi"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "You'll remember from the lecture slides that the model we've fit above is a linear, different slopes design. Try fitting the following models:\n",
        "\n",
        "1. Linear, Same Slopes\n",
        "2. Quadratic, Same Slopes\n",
        "3. Quadratic, Different Slopes\n",
        "\n",
        "Pay attention to the treatment effect. Is it consistent across models? Which model has the highest treatment effect? Which model fits the best?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhITvIN6Otmi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-gsKGodOtmj"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Now, assess the impact of drinking on motor vehicle accidents (`mva`) and suicide (`suicide`), and compare them to the impact on all-cause mortality (`all`). In each case, run a\n",
        "\n",
        "Which cause of death does drinking appear to have the strongest effect on? Which model specification (e.g. linear, same slope) fits the best?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncYuImrPOtmk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg7DzzOdOtml"
      },
      "source": [
        "### Kernel Weighting\n",
        "\n",
        "Regression Discontinuity relies heavily on the extrapolations properties of linear regression. Since we are looking at the values at the beginning and end of 2 regression lines, we better get those limits right. What can happen is that regression might focus too much on fitting the other data points at the cost of a poor fit at the threshold. If this happens, we might get the wrong measure of the treatment effect.\n",
        "\n",
        "One way to solve this is to give higher weights for the points that are closer to the threshold. There are many ways to do this, but a popular one is to reweight the samples with the **triangular kernel**\n",
        "\n",
        "$\n",
        "K(R, c, h) = \\mathcal{1}\\{|R-c| \\leq h\\} * \\bigg(1-\\frac{|R-c|}{h}\\bigg)\n",
        "$\n",
        "\n",
        "The first part of this kernel is an indicator function to whether we are close to the threshold. How close? This is determined by a bandwidth parameter $h$. The second part of this kernel is a weighting function. As we move away from the threshold, the weights get smaller and smaller. These weights are divided by the bandwidth. If the bandwidth is large, the weights get smaller at a slower rate. If the bandwidth is small, the weights quickly go to zero.\n",
        "\n",
        "To make it easier to understand, here is what the weights look like for this kernel applied to our problem. I've set the bandwidth to be 1 here, meaning we will only consider data from people that are no older than 22 years and no younger than 20 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ81tUeXOtml"
      },
      "outputs": [],
      "source": [
        "def kernel(R, c, h):\n",
        "    indicator = (np.abs(R-c) <= h).astype(float)\n",
        "    return indicator * (1 - np.abs(R-c)/h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvAOItl8Otmn"
      },
      "outputs": [],
      "source": [
        "plt.plot(drinking[\"agecell\"], kernel(drinking[\"agecell\"], c=0, h=1))\n",
        "plt.xlabel(\"agecell\")\n",
        "plt.ylabel(\"Weight\")\n",
        "plt.title(\"Kernel Weight by Age\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyVWZv3OOtmp"
      },
      "source": [
        "If we apply these weights to our original problem, the impact of alcohol gets bigger, at least for all causes. It jumps from 7.6627 to 9.7004. The result remains very significant. Also, notice that I'm using `wls` instead of `ols`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYOiCktVOtmq"
      },
      "outputs": [],
      "source": [
        "model = smf.wls(\"all~agecell*threshold\", rdd_df,\n",
        "                weights=kernel(drinking[\"agecell\"], c=0, h=1)).fit()\n",
        "\n",
        "model.summary().tables[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWJYP6ReOtmt"
      },
      "outputs": [],
      "source": [
        "ax = drinking.plot.scatter(x=\"agecell\", y=\"all\", color=\"C0\")\n",
        "drinking.assign(predictions=model.fittedvalues).plot(x=\"agecell\", y=\"predictions\", ax=ax, color=\"C1\")\n",
        "plt.title(\"Regression Discontinuity (Local Regression)\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixh5kY8_Otmw"
      },
      "source": [
        "And here is what it looks like for the other causes of death. Notice how the regression on the right is more negatively sloped since it disconsiders the right most points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io6crOQ8Otmx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "weights = kernel(drinking[\"agecell\"], c=0, h=1)\n",
        "\n",
        "for p, cause in enumerate([\"all\", \"mva\", \"suicide\"], 1):\n",
        "    ax = plt.subplot(3,1,p)\n",
        "    drinking.plot.scatter(x=\"agecell\", y=cause, ax=ax)\n",
        "    m = smf.wls(f\"{cause}~agecell*threshold\", rdd_df, weights=weights).fit()\n",
        "    ate_pct = 100*((m.params[\"threshold\"] + m.params[\"Intercept\"])/m.params[\"Intercept\"] - 1)\n",
        "    drinking.assign(predictions=m.fittedvalues).plot(x=\"agecell\", y=\"predictions\", ax=ax, color=\"C1\")\n",
        "    plt.title(f\"Impact of Alcohol on Death: {np.round(ate_pct, 2)}%\")\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DBXPDU1Otm0"
      },
      "source": [
        "With the exception of suicide, it looks like adding the kernel weight made the negative impact on alcohol bigger. Once again, if we want to minimize the death rate, we should NOT recommend lowering the legal drinking age, since there is a clear impact of alcohol on the death rates.\n",
        "\n",
        "This simple case covers what happens when regression discontinuity design works perfectly. Next, we will see some diagnostics that we should run in order to check how much we can trust RDD and talk about a topic that is very dear to our heart: the effect of education on earnings.\n",
        "\n",
        "## Sheepskin Effect and Fuzzy RDD\n",
        "\n",
        "When it comes to the effect of education on earnings, there are two major views in economics. The first one is the widely known argument that education increases human capital, increasing productivity and thus, earnings. In this view, education actually changes you for the better. Another view is that education is simply a signaling mechanism. It just puts you through all these hard tests and academic tasks. If you can make it, it signals to the market that you are a good employee. In this way, education doesn't make you more productive. It only tells the market how productive you have always been. What matters here is the diploma. If you have it, you will be paid more. We refer to this as the **sheepskin effect**, since diplomas were printed in sheepskin in the past.\n",
        "\n",
        "To test this hypothesis, [Clark and Martorell](https://faculty.smu.edu/millimet/classes/eco7321/papers/clark%20martorell%202014.pdf) used regression discontinuity to measure the effect of graduating 12th grade on earnings. In order to do that, they had to think about some running variable where students that fall above it graduate and those who fall below it, don't. They found such data in the Texas education system.\n",
        "\n",
        "In order to graduate in Texas, one has to pass an exam. Testing starts at 10th grade and students can do it multiple times, but eventually, they face a last chance exam at the end of 12th grade. The idea was to get data from students who took those last chance exams and compare those that had barely failed it to those that barely passed it. These students will have very similar human capital, but different signaling credentials. Namely, those that barely passed it, will receive a diploma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTOdiaGKOtm2"
      },
      "outputs": [],
      "source": [
        "sheepskin = pd.read_csv(\"./data/sheepskin.csv\")[[\"avgearnings\", \"minscore\", \"receivehsd\", \"n\"]]\n",
        "sheepskin.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vdDGo8NOtm4"
      },
      "source": [
        "Once again, this data is grouped by the running variable. It contains not only the running variable (minscore, already centered at zero) and the outcome (avgearnings), but it also has the probability of receiving a diploma in that score cell and the size of the call (n). So, for example, out of the 12 students in the cell -30 below the score threshold, only 5 were able to get the diploma (12 * 0,416).\n",
        "\n",
        "This means that there is some slippage in the treatment assignment. Some students that are below the passing threshold managed to get the diploma anyway. Here, the regression discontinuity is **fuzzy**, rather than sharp. Notice how the probability of getting the diploma doesn't jump from zero to one at the threshold. But it does jump from something like 50% to 90%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1pyn3JIOtm5"
      },
      "outputs": [],
      "source": [
        "sheepskin.plot.scatter(x=\"minscore\", y=\"receivehsd\", figsize=(10,5))\n",
        "plt.xlabel(\"Test Scores Relative to Cut off\")\n",
        "plt.ylabel(\"Fraction Receiving Diplomas\")\n",
        "plt.title(\"Last-chance Exams\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4y5UnlzOtm8"
      },
      "source": [
        "We can think of fuzzy RD as a sort of non compliance. Passing the threshold should make everyone receive the diploma, but some students, the never takers, don’t get it. Likewise, being below the threshold should prevent you from getting a diploma, but some students, the always takers, manage to get it anyway.\n",
        "\n",
        "Just like when we have the potential outcome, we have the potential treatment status in this situation. $T_1$ is the treatment everyone would have received had they been above the threshold. $T_0$ is the treatment everyone would have received had they been below the threshold. As you've might have noticed, we can think of the **threshold as an Instrumental Variable**. Just as in IV, if we naively estimate the treatment effect, it will be biased towards zero.\n",
        "\n",
        "![img](https://matheusfacure.github.io/python-causality-handbook/_images/rdd.png)\n",
        "\n",
        "The probability of treatment being less than one, even above the threshold, makes the outcome we observe less than the true potential outcome $Y_1$. By the same token, the outcome we observe below the threshold is higher than the true potential outcome $Y_0$. This makes it look like the treatment effect at the threshold is smaller than it actually is and we will have to use IV techniques to correct for that.\n",
        "\n",
        "But first, let's talk about a sanity check we need to run to make sure we can trust our RDD estimates.\n",
        "\n",
        "### The McCrary Test\n",
        "\n",
        "One thing that could break our RDD argument is if people can manipulate where they stand at the threshold. In the sheepskin example this could happen if students just below the threshold found a way around the system to increase their test score by just a bit. Another example is when you need to be below a certain income level to get a government benefit. Some families might lower their income on purpose, just to be just eligible for the program.\n",
        "\n",
        "In these sorts of situations, we tend to see a phenomenon called bunching on the density of the running variable. This means that we will have a lot of entities just above or just below the threshold. To check for that, we can plot the density function of the running variable and see if there are any spikes around the threshold. For our case, the density is given by the `n` column in our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc3z090VOtm-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "ax = plt.subplot(2,1,1)\n",
        "sheepskin.plot.bar(x=\"minscore\", y=\"n\", ax=ax)\n",
        "plt.title(\"McCrary Test\")\n",
        "plt.ylabel(\"Smoothness at the Threshold\")\n",
        "\n",
        "ax = plt.subplot(2,1,2, sharex=ax)\n",
        "sheepskin.replace({1877:1977, 1874:2277}).plot.bar(x=\"minscore\", y=\"n\", ax=ax)\n",
        "plt.xlabel(\"Test Scores Relative to Cut off\")\n",
        "plt.ylabel(\"Spike at the Threshold\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWN5-CzfOtnA"
      },
      "source": [
        "The first plot shows how our data density looks like. As we can see, there are no spikes around the threshold, meaning there is no bunching. Students are not manipulating where they fall on the threshold. Just for illustrative purposes, the second plot shows what bunching would look like if students could manipulate where they fall on the threshold. We would see a spike in the density for the cells just above the threshold, since many students would be on that cell, barely passing the exam.\n",
        "\n",
        "Getting this out of the way, we can go back to estimate the sheepskin effect. As I've said before, the numerator of the Wald estimator can be estimated just like we did in the Sharp RD. Here, we will use as weight the kernel with a bandwidth of 15. Since we also have the cell size, we will multiply the kernel by the sample size to get a final weight for the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_RKmaMnOtnC"
      },
      "outputs": [],
      "source": [
        "sheepsking_rdd = sheepskin.assign(threshold=(sheepskin[\"minscore\"]>0).astype(int))\n",
        "model = smf.wls(\"avgearnings~minscore*threshold\",\n",
        "                sheepsking_rdd,\n",
        "                weights=kernel(sheepsking_rdd[\"minscore\"], c=0, h=15)*sheepsking_rdd[\"n\"]).fit()\n",
        "\n",
        "model.summary().tables[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nQc_TPFOtnE"
      },
      "source": [
        "This is telling us that the effect of a diploma is -97.7571, but this is not statistically significant (P-value of 0.5). If we plot these results, we get a very continuous line at the threshold. More educated people indeed make more money, but there isn't a jump at the point where they receive the 12th grade diploma. This is an argument in favor of the view that says that education increases earnings by making people more productive, rather than being just a signal to the marker. In other words, there is no sheepskin effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrnYdyceOtnK"
      },
      "outputs": [],
      "source": [
        "ax = sheepskin.plot.scatter(x=\"minscore\", y=\"avgearnings\", color=\"C0\")\n",
        "sheepskin.assign(predictions=model.fittedvalues).plot(x=\"minscore\", y=\"predictions\", ax=ax, color=\"C1\", figsize=(8,5))\n",
        "plt.xlabel(\"Test Scores Relative to Cutoff\")\n",
        "plt.ylabel(\"Average Earnings\")\n",
        "plt.title(\"Last-chance Exams\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apJrqXGdOtnM"
      },
      "source": [
        "However, as we know from the way non compliance bias works, this result is biased towards zero. To correct for that, we need to scale it by the first stage and get the Wald estimator. Unfortunately, there isn't a good Python implementation for this, so we will have to do it manually and use bootstrap to get the standard errors.\n",
        "\n",
        "The code below runs the numerator of the Wald estimator just like we did before and also constructs the denominator by replacing the target variable with the treatment variable `receivehsd`. The final step just divides the numerator by the denominator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E98fgfCkOtnN"
      },
      "outputs": [],
      "source": [
        "def wald_rdd(data):\n",
        "    weights=kernel(data[\"minscore\"], c=0, h=15)*data[\"n\"]\n",
        "    denominator = smf.wls(\"receivehsd~minscore*threshold\", data, weights=weights).fit()\n",
        "    numerator = smf.wls(\"avgearnings~minscore*threshold\", data, weights=weights).fit()\n",
        "    return numerator.params[\"threshold\"]/denominator.params[\"threshold\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_O2R8rjOtnO"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "np.random.seed(45)\n",
        "bootstrap_sample = 1000\n",
        "ates = Parallel(n_jobs=4)(delayed(wald_rdd)(sheepsking_rdd.sample(frac=1, replace=True))\n",
        "                          for _ in range(bootstrap_sample))\n",
        "ates = np.array(ates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TavfA6fgOtnQ"
      },
      "source": [
        "With the bootstrap samples, we can plot the distribution of ATEs and see where the 95% confidence interval is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94PMbObBOtnR"
      },
      "outputs": [],
      "source": [
        "sns.distplot(ates, kde=False)\n",
        "plt.vlines(np.percentile(ates, 2.5), 0, 100, linestyles=\"dotted\")\n",
        "plt.vlines(np.percentile(ates, 97.5), 0, 100, linestyles=\"dotted\", label=\"95% CI\")\n",
        "plt.title(\"ATE Bootstrap Distribution\")\n",
        "plt.xlim([-10000, 10000])\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8g2387pOtnn"
      },
      "source": [
        "As you can see, even when we scale the effect by the first stage, it is still not statistically different from zero. This means that education doesn't increase earnings by a simple sheepskin effect, but rather by increasing one's productivity.\n",
        "\n",
        "## Key Ideas\n",
        "\n",
        "We learned how to take advantage of artificial discontinuities to estimate causal effects. The idea is that we will have some artificial threshold that makes the probability of treatment jump. One example that we saw was how age makes the probability of drinking jump at 21 years. We could use that to estimate the impact of drinking on mortality rate. We use the fact that very close to the threshold, we have something close to a randomized trial. Entities very close to the threshold could have gone either way and what determines where they've landed is essentially random. With this, we can compare those just above and just below to get the treatment effect. We saw how we could do that with weighted linear regression using a kernel and how this even gave us, for free, standard errors for our ATE.\n",
        "\n",
        "Then, we look at what would happen in the fuzzy RD design, where we have non compliance. We saw how we could approach the situation much like we did with IV.\n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        "This workshop is a modification of Chapter 16 of the handbook [Causal Inference for the Brave and True](https://github.com/matheusfacure/python-causality-handbook).\n",
        "\n",
        "I like to think of this entire book as a tribute to Joshua Angrist, Alberto Abadie and Christopher Walters for their amazing Econometrics class. Most of the ideas here are taken from their classes at the American Economic Association. Watching them is what is keeping me sane during this tough year of 2020.\n",
        "* [Cross-Section Econometrics](https://www.aeaweb.org/conference/cont-ed/2017-webcasts)\n",
        "* [Mastering Mostly Harmless Econometrics](https://www.aeaweb.org/conference/cont-ed/2020-webcasts)\n",
        "\n",
        "I'll also like to reference the amazing books from Angrist. They have shown me that Econometrics, or 'Metrics as they call it, is not only extremely useful but also profoundly fun.\n",
        "\n",
        "* [Mostly Harmless Econometrics](https://www.mostlyharmlesseconometrics.com/)\n",
        "* [Mastering 'Metrics](https://www.masteringmetrics.com/)\n",
        "\n",
        "Other important reference is Miguel Hernan and Jamie Robins' book. It has been my trustworthy companion in the most thorny causal questions I had to answer.\n",
        "\n",
        "* [Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)\n",
        "\n",
        "\n",
        "## Contribute\n",
        "\n",
        "Causal Inference for the Brave and True is an open-source material on causal inference, the statistics of science. It uses only free software, based in Python. Its goal is to be accessible monetarily and intellectually.\n",
        "If you found this book valuable and you want to support it, please go to [Patreon](https://www.patreon.com/causal_inference_for_the_brave_and_true). If you are not ready to contribute financially, you can also help by fixing typos, suggesting edits or giving feedback on passages you didn't understand. Just go to the book's repository and [open an issue](https://github.com/matheusfacure/python-causality-handbook/issues). Finally, if you liked this content, please share it with others who might find it useful and give it a [star on GitHub](https://github.com/matheusfacure/python-causality-handbook/stargazers)."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('geo')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ee0682e3aec3eb14c273afe4405335ee3a64a018407db16d950813fa3a05036"
      }
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fcdab42e4ff84260b4f022902bf5fbbb": {
          "model_module": "jupyter-leaflet",
          "model_name": "LeafletMapModel",
          "model_module_version": "^0.18",
          "state": {
            "_dom_classes": [],
            "_model_module": "jupyter-leaflet",
            "_model_module_version": "^0.18",
            "_model_name": "LeafletMapModel",
            "_view_count": null,
            "_view_module": "jupyter-leaflet",
            "_view_module_version": "^0.18",
            "_view_name": "LeafletMapView",
            "bottom": 1588794,
            "bounce_at_zoom_limits": true,
            "box_zoom": true,
            "center": [
              39.952780070789665,
              -75.13416767120363
            ],
            "close_popup_on_click": true,
            "controls": [
              "IPY_MODEL_afe2c4d1842e43ca8ed7c6e4753524d4",
              "IPY_MODEL_09b163b94e8b4fde9552a9b64f69ae91"
            ],
            "crs": {
              "name": "EPSG3857",
              "custom": false
            },
            "default_style": "IPY_MODEL_711a03f92da241ac8974432c9cf4ae4f",
            "double_click_zoom": true,
            "dragging": true,
            "dragging_style": "IPY_MODEL_afa1c7a4f62c4c3588fd3b862731538e",
            "east": -75.08339881896974,
            "fullscreen": false,
            "inertia": true,
            "inertia_deceleration": 3000,
            "inertia_max_speed": 1500,
            "interpolation": "bilinear",
            "keyboard": true,
            "keyboard_pan_offset": 80,
            "keyboard_zoom_offset": 1,
            "layers": [
              "IPY_MODEL_8252e0c36b434711891ee0428a7aba1e"
            ],
            "layout": "IPY_MODEL_fad647645d244b648fbb6a00559f178a",
            "left": 1221184,
            "max_zoom": null,
            "min_zoom": null,
            "modisdate": "2023-12-13",
            "north": 39.96593791856055,
            "options": [
              "bounce_at_zoom_limits",
              "box_zoom",
              "center",
              "close_popup_on_click",
              "double_click_zoom",
              "dragging",
              "fullscreen",
              "inertia",
              "inertia_deceleration",
              "inertia_max_speed",
              "interpolation",
              "keyboard",
              "keyboard_pan_offset",
              "keyboard_zoom_offset",
              "max_zoom",
              "min_zoom",
              "prefer_canvas",
              "scroll_wheel_zoom",
              "tap",
              "tap_tolerance",
              "touch_zoom",
              "world_copy_jump",
              "zoom",
              "zoom_animation_threshold",
              "zoom_delta",
              "zoom_snap"
            ],
            "panes": {},
            "prefer_canvas": false,
            "right": 1222367,
            "scroll_wheel_zoom": false,
            "south": 39.939619691290005,
            "style": "IPY_MODEL_711a03f92da241ac8974432c9cf4ae4f",
            "tap": true,
            "tap_tolerance": 15,
            "top": 1588394,
            "touch_zoom": true,
            "west": -75.18493652343751,
            "window_url": "https://j8gx6jex0fd-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab_20231212-060125_RC00_590157039",
            "world_copy_jump": false,
            "zoom": 14,
            "zoom_animation_threshold": 4,
            "zoom_delta": 1,
            "zoom_snap": 1
          }
        },
        "afe2c4d1842e43ca8ed7c6e4753524d4": {
          "model_module": "jupyter-leaflet",
          "model_name": "LeafletZoomControlModel",
          "model_module_version": "^0.18",
          "state": {
            "_model_module": "jupyter-leaflet",
            "_model_module_version": "^0.18",
            "_model_name": "LeafletZoomControlModel",
            "_view_count": null,
            "_view_module": "jupyter-leaflet",
            "_view_module_version": "^0.18",
            "_view_name": "LeafletZoomControlView",
            "options": [
              "position",
              "zoom_in_text",
              "zoom_in_title",
              "zoom_out_text",
              "zoom_out_title"
            ],
            "position": "topleft",
            "zoom_in_text": "+",
            "zoom_in_title": "Zoom in",
            "zoom_out_text": "-",
            "zoom_out_title": "Zoom out"
          }
        },
        "09b163b94e8b4fde9552a9b64f69ae91": {
          "model_module": "jupyter-leaflet",
          "model_name": "LeafletAttributionControlModel",
          "model_module_version": "^0.18",
          "state": {
            "_model_module": "jupyter-leaflet",
            "_model_module_version": "^0.18",
            "_model_name": "LeafletAttributionControlModel",
            "_view_count": null,
            "_view_module": "jupyter-leaflet",
            "_view_module_version": "^0.18",
            "_view_name": "LeafletAttributionControlView",
            "options": [
              "position",
              "prefix"
            ],
            "position": "bottomright",
            "prefix": "ipyleaflet"
          }
        },
        "711a03f92da241ac8974432c9cf4ae4f": {
          "model_module": "jupyter-leaflet",
          "model_name": "LeafletMapStyleModel",
          "model_module_version": "^0.18",
          "state": {
            "_model_module": "jupyter-leaflet",
            "_model_module_version": "^0.18",
            "_model_name": "LeafletMapStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "cursor": "grab"
          }
        },
        "afa1c7a4f62c4c3588fd3b862731538e": {
          "model_module": "jupyter-leaflet",
          "model_name": "LeafletMapStyleModel",
          "model_module_version": "^0.18",
          "state": {
            "_model_module": "jupyter-leaflet",
            "_model_module_version": "^0.18",
            "_model_name": "LeafletMapStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "cursor": "move"
          }
        },
        "8252e0c36b434711891ee0428a7aba1e": {
          "model_module": "jupyter-leaflet",
          "model_name": "LeafletTileLayerModel",
          "model_module_version": "^0.18",
          "state": {
            "_model_module": "jupyter-leaflet",
            "_model_module_version": "^0.18",
            "_model_name": "LeafletTileLayerModel",
            "_view_count": null,
            "_view_module": "jupyter-leaflet",
            "_view_module_version": "^0.18",
            "_view_name": "LeafletTileLayerView",
            "attribution": "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community",
            "base": true,
            "bottom": true,
            "bounds": null,
            "detect_retina": false,
            "loading": false,
            "max_native_zoom": null,
            "max_zoom": 18,
            "min_native_zoom": null,
            "min_zoom": 1,
            "name": "Esri.WorldImagery",
            "no_wrap": false,
            "opacity": 1,
            "options": [
              "attribution",
              "bounds",
              "detect_retina",
              "max_native_zoom",
              "max_zoom",
              "min_native_zoom",
              "min_zoom",
              "no_wrap",
              "tile_size",
              "tms",
              "zoom_offset"
            ],
            "pane": "",
            "popup": null,
            "popup_max_height": null,
            "popup_max_width": 300,
            "popup_min_width": 50,
            "show_loading": false,
            "subitems": [],
            "tile_size": 256,
            "tms": false,
            "url": "https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}",
            "visible": true,
            "zoom_offset": 0
          }
        },
        "fad647645d244b648fbb6a00559f178a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "306361b3b81449ffa99c5a3ae577d3e0": {
          "model_module": "jupyter-leaflet",
          "model_name": "LeafletMapStyleModel",
          "model_module_version": "^0.18",
          "state": {
            "_model_module": "jupyter-leaflet",
            "_model_module_version": "^0.18",
            "_model_name": "LeafletMapStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "cursor": "grab"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}